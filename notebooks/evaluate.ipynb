{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_path = \"../NeuralNLP-NeuralClassifier-master/data/cpc_label_tree.pkl\"\n",
    "predicted_path = \"../../../../predict.txt\"\n",
    "truth_path = \"../../../../test.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pickle\n",
    "import copy\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_confusion_to_dict(cur_dict, in_predicted, in_true):\n",
    "    \n",
    "    # this is necessary because the metric can be zero and \n",
    "    # the key would not exist if the metric is zero\n",
    "    for metric in ['tp', 'tn', 'fp', 'fn']:\n",
    "        if metric not in cur_dict:\n",
    "            cur_dict[metric] = 0\n",
    "    \n",
    "    if in_predicted and in_true:\n",
    "        cur_dict['tp'] += 1\n",
    "    elif in_predicted and not in_true:\n",
    "        cur_dict['fp'] += 1\n",
    "    elif not in_predicted and in_true:\n",
    "        cur_dict['fn'] += 1\n",
    "    else:\n",
    "        cur_dict['tn'] += 1\n",
    "        \n",
    "def update_metrics_tracker(metrics_tracker, index, cur_dict):\n",
    "    \n",
    "    for metric in ['tp', 'tn', 'fp', 'fn']:\n",
    "        metrics_tracker[index][metric] += cur_dict[metric]\n",
    "    \n",
    "    tp = cur_dict['tp']\n",
    "    tn = cur_dict['tn']\n",
    "    fp = cur_dict['fp']\n",
    "    fn = cur_dict['fn']\n",
    "    \n",
    "    # https://github.com/dice-group/gerbil/wiki/Precision,-Recall-and-F1-measure\n",
    "    # For these special cases, we have defined that if the true positives, \n",
    "    # false positives and false negatives are all 0, the precision, recall and F1-measure are 1. \n",
    "    # This might occur in cases in which the gold standard contains a document without any annotations \n",
    "    # and the annotator (correctly) returns no annotations. If true positives are 0 and \n",
    "    # one of the two other counters is larger than 0, the precision, recall and F1-measure are 0.\n",
    "    \n",
    "    if tp == 0 and fp == 0 and fn == 0:\n",
    "        precision = 1\n",
    "        recall = 1\n",
    "        f1 = 1\n",
    "    elif tp == 0 and (fp > 0 or fn > 0):\n",
    "        precision = 0\n",
    "        recall = 0\n",
    "        f1 = 0\n",
    "    # non-special cases\n",
    "    else:\n",
    "        precision = tp / (tp + fp)\n",
    "        recall = tp / (tp + fn)\n",
    "        f1 = (2 * precision * recall) / (precision + recall)\n",
    "\n",
    "    metrics_tracker[index]['precisions'].append(precision)\n",
    "    metrics_tracker[index]['recalls'].append(recall)\n",
    "    metrics_tracker[index]['f1s'].append(f1)\n",
    "\n",
    "    \n",
    "def pretty_print_describe(stats):\n",
    "    \n",
    "    for metric in ['mean', 'std', 'min', '50%', 'max']:\n",
    "        print(\"      {}:\\t{}\".format(metric, stats[metric]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_evaluation_results(tree_path, predicted_path, truth_path):\n",
    "    with open(tree_path, 'rb') as f:\n",
    "        tree_dict = pickle.load(f)\n",
    "\n",
    "\n",
    "    with open(predicted_path, 'r') as predicted_file, open(truth_path, 'r') as truth_file:  \n",
    "        \n",
    "        for predicted in predicted_file:\n",
    "            truth = next(truth_file)\n",
    "\n",
    "            predicted_labels = predicted.strip().split(\";\")\n",
    "            true_labels = json.loads(truth)[\"doc_label\"]\n",
    "\n",
    "            predicted_level_tracker = [set() for _ in range(5)]\n",
    "            true_level_tracker = [set() for _ in range(5)]\n",
    "\n",
    "            # get tracker\n",
    "            for predicted_label in predicted_labels:\n",
    "                index = 0\n",
    "                for level_label in predicted_label.split(\"--\"):\n",
    "                    predicted_level_tracker[index].add(level_label)\n",
    "                    index += 1\n",
    "\n",
    "            for true_label in true_labels:\n",
    "                index = 0\n",
    "                for level_label in true_label.split(\"--\"):\n",
    "                    true_level_tracker[index].add(level_label)\n",
    "                    index += 1\n",
    "\n",
    "            # traverse tree\n",
    "            root_dict = tree_dict['Root']\n",
    "\n",
    "            for cpc_section, section_dict in root_dict.items():\n",
    "\n",
    "                if cpc_section not in ['tp', 'tn', 'fp', 'fn']:\n",
    "                    in_predicted = cpc_section in predicted_level_tracker[0]\n",
    "                    in_true = cpc_section in true_level_tracker[0]\n",
    "                    add_confusion_to_dict(section_dict, in_predicted, in_true)\n",
    "\n",
    "                    for cpc_class, class_dict in section_dict.items():\n",
    "\n",
    "                        if cpc_class not in ['tp', 'tn', 'fp', 'fn']:\n",
    "                            in_predicted = cpc_class in predicted_level_tracker[1]\n",
    "                            in_true = cpc_class in true_level_tracker[1]\n",
    "                            add_confusion_to_dict(class_dict, in_predicted, in_true)\n",
    "\n",
    "                            for cpc_subclass, subclass_dict in class_dict.items():\n",
    "\n",
    "                                if cpc_subclass not in ['tp', 'tn', 'fp', 'fn']:\n",
    "                                    in_predicted = cpc_subclass in predicted_level_tracker[2]\n",
    "                                    in_true = cpc_subclass in true_level_tracker[2]\n",
    "                                    add_confusion_to_dict(subclass_dict, in_predicted, in_true)\n",
    "                                    \n",
    "    # calculate tp fp tn fn\n",
    "    metrics_tracker = [{'tp': 0, 'fp': 0, \n",
    "                        'tn': 0, 'fn': 0, \n",
    "                        'precisions': [], 'recalls': [], 'f1s': []} for _ in range(5)]\n",
    "    \n",
    "    root_dict = tree_dict['Root']\n",
    "\n",
    "    for cpc_section, section_dict in root_dict.items():\n",
    "\n",
    "        if cpc_section not in ['tp', 'tn', 'fp', 'fn']:\n",
    "            update_metrics_tracker(metrics_tracker, 0, section_dict)\n",
    "\n",
    "            for cpc_class, class_dict in section_dict.items():\n",
    "\n",
    "                if cpc_class not in ['tp', 'tn', 'fp', 'fn']:\n",
    "                    update_metrics_tracker(metrics_tracker, 1, class_dict)\n",
    "\n",
    "                    for cpc_subclass, subclass_dict in class_dict.items():\n",
    "\n",
    "                        if cpc_subclass not in ['tp', 'tn', 'fp', 'fn']:\n",
    "                            update_metrics_tracker(metrics_tracker, 2, subclass_dict)\n",
    "    \n",
    "    for i in range(3):\n",
    "        print(\"level {}:\".format(i+1))\n",
    "        level_metrics_tracker = metrics_tracker[i]\n",
    "        print(\"  macro:\")\n",
    "        print(\"    precision:\")\n",
    "        pretty_print_describe(pd.Series(level_metrics_tracker['precisions']).describe())\n",
    "        print(\"    recall:\")\n",
    "        pretty_print_describe(pd.Series(level_metrics_tracker['recalls']).describe())\n",
    "        print(\"    f1:\")\n",
    "        pretty_print_describe(pd.Series(level_metrics_tracker['f1s']).describe())\n",
    "        print(\"  micro:\")\n",
    "\n",
    "        tp = level_metrics_tracker['tp']\n",
    "        tn = level_metrics_tracker['tn']\n",
    "        fp = level_metrics_tracker['fp']\n",
    "        fn = level_metrics_tracker['fn']\n",
    "        precision = tp / (tp + fp)\n",
    "        recall = tp / (tp + fn)\n",
    "        f1 = (2 * precision * recall) / (precision + recall)\n",
    "\n",
    "        print(\"    precision:\\t{}\".format(precision))\n",
    "        print(\"    recall:\\t{}\".format(recall))\n",
    "        print(\"    f1:\\t\\t{}\".format(f1))\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level 1:\n",
      "  macro:\n",
      "    precision:\n",
      "      mean:\t0.18277834924597014\n",
      "      std:\t0.0950387671537092\n",
      "      min:\t0.053029507508138195\n",
      "      50%:\t0.17889946490189867\n",
      "      max:\t0.32995907458448176\n",
      "    recall:\n",
      "      mean:\t0.9623123793287331\n",
      "      std:\t0.08405541456498014\n",
      "      min:\t0.7448377581120944\n",
      "      50%:\t0.996999322427645\n",
      "      max:\t1.0\n",
      "    f1:\n",
      "      mean:\t0.29911400546192374\n",
      "      std:\t0.13534696721502898\n",
      "      min:\t0.09900990099009903\n",
      "      50%:\t0.30349391287134314\n",
      "      max:\t0.49619432791579793\n",
      "  micro:\n",
      "    precision:\t0.20764828182306633\n",
      "    recall:\t0.9946957319666078\n",
      "    f1:\t\t0.343573648324804\n",
      "\n",
      "level 2:\n",
      "  macro:\n",
      "    precision:\n",
      "      mean:\t0.04439217424789303\n",
      "      std:\t0.0901732811172928\n",
      "      min:\t0.0\n",
      "      50%:\t0.027574223766714513\n",
      "      max:\t1.0\n",
      "    recall:\n",
      "      mean:\t0.7086050862040237\n",
      "      std:\t0.257600501579483\n",
      "      min:\t0.0\n",
      "      50%:\t0.7824427480916031\n",
      "      max:\t1.0\n",
      "    f1:\n",
      "      mean:\t0.07595782480970638\n",
      "      std:\t0.09813426037780547\n",
      "      min:\t0.0\n",
      "      50%:\t0.05286940804338003\n",
      "      max:\t1.0\n",
      "  micro:\n",
      "    precision:\t0.05920780365103293\n",
      "    recall:\t0.94024946219582\n",
      "    f1:\t\t0.11140067203075348\n",
      "\n",
      "level 3:\n",
      "  macro:\n",
      "    precision:\n",
      "      mean:\t0.056226129399183096\n",
      "      std:\t0.17620275150378037\n",
      "      min:\t0.0\n",
      "      50%:\t0.01950738527988398\n",
      "      max:\t1.0\n",
      "    recall:\n",
      "      mean:\t0.5542097694051841\n",
      "      std:\t0.33173294167598355\n",
      "      min:\t0.0\n",
      "      50%:\t0.6159114857744995\n",
      "      max:\t1.0\n",
      "    f1:\n",
      "      mean:\t0.07539790055210217\n",
      "      std:\t0.17544361531376917\n",
      "      min:\t0.0\n",
      "      50%:\t0.037524755960661654\n",
      "      max:\t1.0\n",
      "  micro:\n",
      "    precision:\t0.034473\n",
      "    recall:\t0.881489563001287\n",
      "    f1:\t\t0.06635116091595256\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_evaluation_results(tree_path, predicted_path, truth_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level 1:\n",
      "  macro:\n",
      "    precision:\n",
      "      mean:\t0.8586884618775475\n",
      "      std:\t0.10046112566502963\n",
      "      min:\t0.5981203007518797\n",
      "      50%:\t0.891543178334185\n",
      "      max:\t0.9264069264069265\n",
      "    recall:\n",
      "      mean:\t0.5688828683547849\n",
      "      std:\t0.17636600592400353\n",
      "      min:\t0.2964412148313769\n",
      "      50%:\t0.5916878172588832\n",
      "      max:\t0.7911487355336476\n",
      "    f1:\n",
      "      mean:\t0.6731226963512075\n",
      "      std:\t0.15188459541653226\n",
      "      min:\t0.39641210913168057\n",
      "      50%:\t0.7125119388729703\n",
      "      max:\t0.8265323257766582\n",
      "  micro:\n",
      "    precision:\t0.8600873600873601\n",
      "    recall:\t0.6345985989570511\n",
      "    f1:\t\t0.7303343292808572\n",
      "\n",
      "level 2:\n",
      "  macro:\n",
      "    precision:\n",
      "      mean:\t0.7587013609338736\n",
      "      std:\t0.2165222688309608\n",
      "      min:\t0.0\n",
      "      50%:\t0.803448275862069\n",
      "      max:\t1.0\n",
      "    recall:\n",
      "      mean:\t0.3543226008506042\n",
      "      std:\t0.21700703386334672\n",
      "      min:\t0.0\n",
      "      50%:\t0.3333333333333333\n",
      "      max:\t1.0\n",
      "    f1:\n",
      "      mean:\t0.4535701773810979\n",
      "      std:\t0.22725942775417868\n",
      "      min:\t0.0\n",
      "      50%:\t0.46226415094339623\n",
      "      max:\t1.0\n",
      "  micro:\n",
      "    precision:\t0.7990031807338407\n",
      "    recall:\t0.5552606129980856\n",
      "    f1:\t\t0.6551973079027956\n",
      "\n",
      "level 3:\n",
      "  macro:\n",
      "    precision:\n",
      "      mean:\t0.5441070810720233\n",
      "      std:\t0.3414280700245939\n",
      "      min:\t0.0\n",
      "      50%:\t0.6458978328173375\n",
      "      max:\t1.0\n",
      "    recall:\n",
      "      mean:\t0.28857167833286756\n",
      "      std:\t0.26703420948895007\n",
      "      min:\t0.0\n",
      "      50%:\t0.24490203918432626\n",
      "      max:\t1.0\n",
      "    f1:\n",
      "      mean:\t0.346439573176553\n",
      "      std:\t0.27882984119721255\n",
      "      min:\t0.0\n",
      "      50%:\t0.3510338345864662\n",
      "      max:\t1.0\n",
      "  micro:\n",
      "    precision:\t0.6879678634434749\n",
      "    recall:\t0.49193252814878585\n",
      "    f1:\t\t0.57366498521482\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_evaluation_results(tree_path, \"../../../../model2_predict.txt\", truth_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level 1:\n",
      "  macro:\n",
      "    precision:\n",
      "      mean:\t0.6927069460817629\n",
      "      std:\t0.10431756023040202\n",
      "      min:\t0.4500542888165038\n",
      "      50%:\t0.7118055555555556\n",
      "      max:\t0.8060626549470363\n",
      "    recall:\n",
      "      mean:\t0.7862272868566605\n",
      "      std:\t0.13090079065086824\n",
      "      min:\t0.5406185951183157\n",
      "      50%:\t0.8166787644164852\n",
      "      max:\t0.9231675953707672\n",
      "    f1:\n",
      "      mean:\t0.734307782406566\n",
      "      std:\t0.10984436409922531\n",
      "      min:\t0.4911968850516336\n",
      "      50%:\t0.7443631039531479\n",
      "      max:\t0.8307781649245064\n",
      "  micro:\n",
      "    precision:\t0.6993252514928693\n",
      "    recall:\t0.8269398625814104\n",
      "    f1:\t\t0.7577974783495955\n",
      "\n",
      "level 2:\n",
      "  macro:\n",
      "    precision:\n",
      "      mean:\t0.6513888507830401\n",
      "      std:\t0.20501617252990478\n",
      "      min:\t0.0\n",
      "      50%:\t0.6756756756756757\n",
      "      max:\t1.0\n",
      "    recall:\n",
      "      mean:\t0.4343691284571295\n",
      "      std:\t0.2357339277919186\n",
      "      min:\t0.0\n",
      "      50%:\t0.44397759103641454\n",
      "      max:\t1.0\n",
      "    f1:\n",
      "      mean:\t0.4935344768787844\n",
      "      std:\t0.22264662083466916\n",
      "      min:\t0.0\n",
      "      50%:\t0.5094339622641509\n",
      "      max:\t1.0\n",
      "  micro:\n",
      "    precision:\t0.7063761308281141\n",
      "    recall:\t0.6410625826442203\n",
      "    f1:\t\t0.672136405491811\n",
      "\n",
      "level 3:\n",
      "  macro:\n",
      "    precision:\n",
      "      mean:\t0.5441070810720233\n",
      "      std:\t0.3414280700245939\n",
      "      min:\t0.0\n",
      "      50%:\t0.6458978328173375\n",
      "      max:\t1.0\n",
      "    recall:\n",
      "      mean:\t0.28857167833286756\n",
      "      std:\t0.26703420948895007\n",
      "      min:\t0.0\n",
      "      50%:\t0.24490203918432626\n",
      "      max:\t1.0\n",
      "    f1:\n",
      "      mean:\t0.346439573176553\n",
      "      std:\t0.27882984119721255\n",
      "      min:\t0.0\n",
      "      50%:\t0.3510338345864662\n",
      "      max:\t1.0\n",
      "  micro:\n",
      "    precision:\t0.6879678634434749\n",
      "    recall:\t0.49193252814878585\n",
      "    f1:\t\t0.57366498521482\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_evaluation_results(tree_path, \"../../../../model2_predict_all.txt\", truth_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level 1:\n",
      "  macro:\n",
      "    precision:\n",
      "      mean:\t0.16909459840873053\n",
      "      std:\t0.10466109926800289\n",
      "      min:\t0.02552974214960429\n",
      "      50%:\t0.17223500383448367\n",
      "      max:\t0.32921666666666666\n",
      "    recall:\n",
      "      mean:\t0.985401793804436\n",
      "      std:\t0.037980061941852196\n",
      "      min:\t0.8849557522123894\n",
      "      50%:\t1.0\n",
      "      max:\t1.0\n",
      "    f1:\n",
      "      mean:\t0.2771141980498963\n",
      "      std:\t0.15302654835091023\n",
      "      min:\t0.04962779156327544\n",
      "      50%:\t0.29385746590246464\n",
      "      max:\t0.49535440673078124\n",
      "  micro:\n",
      "    precision:\t0.18355077367350423\n",
      "    recall:\t0.9986347664555404\n",
      "    f1:\t\t0.31010391817204097\n",
      "\n",
      "level 2:\n",
      "  macro:\n",
      "    precision:\n",
      "      mean:\t0.029591138316574467\n",
      "      std:\t0.08979679541176429\n",
      "      min:\t0.0\n",
      "      50%:\t0.015211879753712423\n",
      "      max:\t1.0\n",
      "    recall:\n",
      "      mean:\t0.8241816900658034\n",
      "      std:\t0.20664932680477244\n",
      "      min:\t0.0\n",
      "      50%:\t0.8972602739726028\n",
      "      max:\t1.0\n",
      "    f1:\n",
      "      mean:\t0.049283685323533166\n",
      "      std:\t0.09579173246168839\n",
      "      min:\t0.0\n",
      "      50%:\t0.029747112995176142\n",
      "      max:\t1.0\n",
      "  micro:\n",
      "    precision:\t0.035721585801085684\n",
      "    recall:\t0.974363022755531\n",
      "    f1:\t\t0.0689165878262484\n",
      "\n",
      "level 3:\n",
      "  macro:\n",
      "    precision:\n",
      "      mean:\t0.03809012806557653\n",
      "      std:\t0.16081546292955748\n",
      "      min:\t0.0\n",
      "      50%:\t0.009445920289641774\n",
      "      max:\t1.0\n",
      "    recall:\n",
      "      mean:\t0.6694663586338474\n",
      "      std:\t0.3172116356518174\n",
      "      min:\t0.0\n",
      "      50%:\t0.7803308823529411\n",
      "      max:\t1.0\n",
      "    f1:\n",
      "      mean:\t0.04854266317686788\n",
      "      std:\t0.16004815043691\n",
      "      min:\t0.0\n",
      "      50%:\t0.018626391449987595\n",
      "      max:\t1.0\n",
      "  micro:\n",
      "    precision:\t0.018309333333333334\n",
      "    recall:\t0.9363551903718793\n",
      "    f1:\t\t0.035916364069708266\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_evaluation_results(tree_path, \"../../../../predict_n100.txt\", truth_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
