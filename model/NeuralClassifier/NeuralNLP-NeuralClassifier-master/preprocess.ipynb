{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "import json\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_API_data(directory):\n",
    "    \n",
    "    master_df = []\n",
    "    counter = 0\n",
    "    for filename in os.listdir(directory):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        with open(file_path, 'rb') as file:\n",
    "            d = pd.DataFrame(pickle.load(file))\n",
    "        master_df.append(d)\n",
    "        counter += 1\n",
    "        print(\"finished processing file {}; count = {}\".format(filename, counter))\n",
    "    return pd.concat(master_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_data_directory = \"data/raw_data\"\n",
    "df_raw = process_API_data(API_data_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice dictionary for cpc field\n",
    "cpc_field_slice_dict = {'kind':                (0 ,2 ),   \n",
    "                        'application_number':  (2 ,10),  \n",
    "                        'document_number':     (10,18),\n",
    "                        'cpc_section':         (18,19), \n",
    "                        'cpc_class':           (18,21), # include higher levels\n",
    "                        'cpc_subclass':        (18,22), # include higher levels\n",
    "                        'cpc_main_group':      (18,26), # include higher levels\n",
    "                        'cpc_subgroup':        (18,33), # include higher levels\n",
    "                        'cpc_version_date':    (33,41), \n",
    "                        'cpc_symbol_position': (41,42), \n",
    "                        'cpc_value_code':      (42,43), \n",
    "                        'cpc_set_group':       (43,46), \n",
    "                        'cpc_set_rank':        (46,48)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of claims\n",
    "len(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_cpc = [y for x in df_raw[\"cpc_codes\"] for y in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "271771"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of labels\n",
    "len(flattened_cpc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create analytics dataset without any text data\n",
    "levels = [\"cpc_section\", \"cpc_class\", \"cpc_subclass\", \"cpc_main_group\", \"cpc_subgroup\"]\n",
    "df_analytics = pd.DataFrame([[cpc[value[0]:value[1]] for key, value in cpc_field_slice_dict.items()] \n",
    "                             for cpc in flattened_cpc],\n",
    "                            columns = list(cpc_field_slice_dict.keys()))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kind</th>\n",
       "      <th>application_number</th>\n",
       "      <th>document_number</th>\n",
       "      <th>cpc_section</th>\n",
       "      <th>cpc_class</th>\n",
       "      <th>cpc_subclass</th>\n",
       "      <th>cpc_main_group</th>\n",
       "      <th>cpc_subgroup</th>\n",
       "      <th>cpc_version_date</th>\n",
       "      <th>cpc_symbol_position</th>\n",
       "      <th>cpc_value_code</th>\n",
       "      <th>cpc_set_group</th>\n",
       "      <th>cpc_set_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>B1</td>\n",
       "      <td>09646314</td>\n",
       "      <td>6405541</td>\n",
       "      <td>F</td>\n",
       "      <td>F25</td>\n",
       "      <td>F25J</td>\n",
       "      <td>F25J   1</td>\n",
       "      <td>F25J   1/001</td>\n",
       "      <td>20130101</td>\n",
       "      <td>F</td>\n",
       "      <td>I</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>B1</td>\n",
       "      <td>09646314</td>\n",
       "      <td>6405541</td>\n",
       "      <td>F</td>\n",
       "      <td>F25</td>\n",
       "      <td>F25J</td>\n",
       "      <td>F25J   1</td>\n",
       "      <td>F25J   1/0221</td>\n",
       "      <td>20130101</td>\n",
       "      <td>L</td>\n",
       "      <td>I</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>B1</td>\n",
       "      <td>09646314</td>\n",
       "      <td>6405541</td>\n",
       "      <td>F</td>\n",
       "      <td>F25</td>\n",
       "      <td>F25J</td>\n",
       "      <td>F25J   1</td>\n",
       "      <td>F25J   1/0275</td>\n",
       "      <td>20130101</td>\n",
       "      <td>L</td>\n",
       "      <td>I</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>B1</td>\n",
       "      <td>09646314</td>\n",
       "      <td>6405541</td>\n",
       "      <td>B</td>\n",
       "      <td>B64</td>\n",
       "      <td>B64G</td>\n",
       "      <td>B64G   1</td>\n",
       "      <td>B64G   1/402</td>\n",
       "      <td>20130101</td>\n",
       "      <td>L</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>B1</td>\n",
       "      <td>09646314</td>\n",
       "      <td>6405541</td>\n",
       "      <td>F</td>\n",
       "      <td>F25</td>\n",
       "      <td>F25J</td>\n",
       "      <td>F25J2205</td>\n",
       "      <td>F25J2205/20</td>\n",
       "      <td>20130101</td>\n",
       "      <td>L</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  kind application_number document_number cpc_section cpc_class cpc_subclass  \\\n",
       "0   B1           09646314         6405541           F       F25         F25J   \n",
       "1   B1           09646314         6405541           F       F25         F25J   \n",
       "2   B1           09646314         6405541           F       F25         F25J   \n",
       "3   B1           09646314         6405541           B       B64         B64G   \n",
       "4   B1           09646314         6405541           F       F25         F25J   \n",
       "\n",
       "  cpc_main_group     cpc_subgroup cpc_version_date cpc_symbol_position  \\\n",
       "0       F25J   1  F25J   1/001            20130101                   F   \n",
       "1       F25J   1  F25J   1/0221           20130101                   L   \n",
       "2       F25J   1  F25J   1/0275           20130101                   L   \n",
       "3       B64G   1  B64G   1/402            20130101                   L   \n",
       "4       F25J2205  F25J2205/20             20130101                   L   \n",
       "\n",
       "  cpc_value_code cpc_set_group cpc_set_rank  \n",
       "0              I             0            0  \n",
       "1              I             0            0  \n",
       "2              I             0            0  \n",
       "3              A             0            0  \n",
       "4              A             0            0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_analytics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique cpc_section: 9\n",
      "number of unique cpc_class: 128\n",
      "number of unique cpc_subclass: 634\n",
      "number of unique cpc_main_group: 7222\n",
      "number of unique cpc_subgroup: 83304\n"
     ]
    }
   ],
   "source": [
    "# number of unique values at differente levels\n",
    "unique_label_dict = {}\n",
    "for level in levels:\n",
    "    unique_label_dict[level] = set(df_analytics[level])\n",
    "    print(\"number of unique \" + level + \": \" + str(len(unique_label_dict[level])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw[\"num_label\"] = df_raw[\"cpc_codes\"].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1237"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# percent of patents with one label\n",
    "len(df_raw[df_raw[\"num_label\"] == 1]) / len(df_raw[\"num_label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5810</td>\n",
       "      <td>14.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5138</td>\n",
       "      <td>12.8%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4948</td>\n",
       "      <td>12.4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4299</td>\n",
       "      <td>10.7%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3409</td>\n",
       "      <td>8.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>181</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>167</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>124 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     count      %\n",
       "2     5810  14.5%\n",
       "3     5138  12.8%\n",
       "1     4948  12.4%\n",
       "4     4299  10.7%\n",
       "5     3409   8.5%\n",
       "..     ...    ...\n",
       "181      1   0.0%\n",
       "167      1   0.0%\n",
       "134      1   0.0%\n",
       "135      1   0.0%\n",
       "78       1   0.0%\n",
       "\n",
       "[124 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([df_raw[\"num_label\"].value_counts(),\n",
    "           df_raw[\"num_label\"].value_counts(normalize=True).mul(100)\n",
    "           .round(1).astype(str)+\"%\"], axis=1, keys=['count', '%'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_column values: ['title', 'abstraction', 'claims', 'brief_summary', 'description']\n",
    "text_columns = ['title', 'abstraction', 'claims']\n",
    "\n",
    "# label_columns values: ['cpc_section', 'cpc_class', 'cpc_subclass', 'cpc_main_group', 'cpc_subgroup']\n",
    "label_columns = ['cpc_section', 'cpc_class', 'cpc_subclass']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_labels(cpc_codes, label_columns):\n",
    "    labels = set()\n",
    "    for cpc_code in cpc_codes:\n",
    "        level_label = []\n",
    "        for label_column in label_columns:\n",
    "            index = cpc_field_slice_dict[label_column]\n",
    "            level_label.append(cpc_code[index[0]:index[1]])\n",
    "        labels.add(\"--\".join(level_label))\n",
    "    return list(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    return [token.lower() for token in tokens if token not in string.punctuation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_data(text_columns, label_columns, folder):\n",
    "    df_text = pd.DataFrame(df_raw['cpc_codes'].apply(extract_labels, args=(label_columns,)))\n",
    "    df_text['doc_token'] = df_raw[text_columns].agg(' '.join, axis=1).apply(tokenize)\n",
    "    df_text.columns = ['doc_label', 'doc_token']\n",
    "    \n",
    "    df_train, df_valid_test = train_test_split(df_text, test_size=0.3, random_state=1)\n",
    "    df_valid, df_test = train_test_split(df_valid_test, test_size=0.333, random_state=1)\n",
    "    \n",
    "    df_train.to_json(folder + \"/train.json\", orient='records')\n",
    "    df_valid.to_json(folder + \"/valid.json\", orient='records')\n",
    "    df_test.to_json(folder + \"/test.json\", orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_data(text_columns, label_columns, 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'doc_label': ['B--B64--B64G', 'F--F25--F25J'], 'doc_token': ['method', 'and', 'device', 'for', 'the', 'production', 'of', 'slush', 'from', 'liquefied', 'gas', 'a', 'method', 'for', 'producing', 'slush', 'from', 'liquefied', 'gas', 'wherein', 'solid', 'crystals', 'are', 'formed', 'and', 'mixed', 'with', 'the', 'liquefied', 'gas', 'to', 'produce', 'slush', 'the', 'solid', 'crystals', 'are', 'produced', 'from', 'liquid', 'particles', 'which', 'are', 'released', 'into', 'or', 'enter', 'a', 'gas', 'atmosphere', 'under', 'pressure', 'wherein', 'the', 'temperature', 'of', 'the', 'gas', 'atmosphere', 'is', 'below', 'the', 'freezing', 'point', 'of', 'the', 'liquid', 'particles', 'a', 'device', 'is', 'also', 'provided', 'for', 'producing', 'the', 'slush', 'from', 'liquefied', 'gas', 'in', 'a', 'cryostat', 'container', 'which', 'is', 'partly', 'filled', 'with', 'the', 'liquefied', 'gas', 'which', 'mixes', 'with', 'the', 'solid', 'crystals', 'to', 'produce', 'slush', 'the', 'device', 'has', 'an', 'atomizing', 'device', 'for', 'producing', 'the', 'liquid', 'particles', 'from', 'the', 'liquefied', 'gas', 'supplied', 'to', 'it', 'the', 'liquid', 'particles', 'enter', 'a', 'gas', 'atmosphere', 'which', 'exists', 'above', 'the', 'liquefied', 'gas', 'in', 'the', 'container', 'a', 'method', 'for', 'producing', 'slush', 'from', 'liquefied', 'gas', 'by', 'which', 'solid', 'crystals', 'are', 'formed', 'which', 'mix', 'with', 'the', 'liquefied', 'gas', 'to', 'produce', 'slush', 'characterized', 'by', 'the', 'release', 'or', 'admission', 'to', 'a', 'gas', 'atmosphere', 'of', 'pressurized', 'solid', 'crystals', 'formed', 'from', 'liquid', 'particles', 'which', 'has', 'a', 'temperature', 'below', 'the', 'freezing', 'point', 'of', 'the', 'liquid', 'particles', 'and', 'the', 'liquid', 'particles', 'being', 'formed', 'by', 'atomization', 'of', 'the', 'liquified', 'gas', 'method', 'according', 'to', 'claim', '1', 'characterized', 'by', 'atomization', 'is', 'effected', 'by', 'means', 'of', 'an', 'atomizing', 'device', '12', 'which', 'comprises', 'a', 'nozzle', '15a', 'a', 'centrifugal', 'and', 'mixing', 'chamber', 'method', 'according', 'to', 'claim', '2', 'characterized', 'by', 'atomization', 'is', 'effected', 'at', 'least', 'partly', 'by', 'means', 'of', 'a', 'pressurized', 'gas', 'supplied', 'to', 'the', 'nozzle', 'a', 'centrifugal', 'and', 'mixing', 'chamber', 'method', 'according', 'to', 'claim', '3', 'characterized', 'by', 'this', 'gas', 'of', 'the', 'gaseous', 'phase', 'corresponding', 'to', 'the', 'supplied', 'liquefied', 'gas', 'method', 'according', 'to', 'claim', '4', 'characterized', 'by', 'the', 'liquefied', 'gas', 'supplied', 'to', 'the', 'atomizing', 'device', '12', 'being', 'cooled', 'down', 'before', 'atomization', 'by', 'means', 'of', 'a', 'gaseous', 'cooling', 'medium', 'method', 'according', 'to', 'claim', '2', 'characterized', 'by', 'atomization', 'being', 'effected', 'at', 'least', 'partly', 'at', 'the', 'discharge', 'of', 'liquefied', 'gas', 'into', 'the', 'cold', 'gas', 'atmosphere', 'method', 'according', 'to', 'claim', '6', 'characterized', 'by', 'pressure', 'in', 'the', 'cold', 'gas', 'atmosphere', 'being', 'set', 'lower', 'than', 'the', 'corresponding', 'critical', 'pressure', 'in', 'the', 'discharge', 'aperture', 'of', 'the', 'nozzle', 'a', 'of', 'the', 'atomizing', 'device', '2', '12', 'method', 'according', 'to', 'claim', '7', 'characterized', 'by', 'pressure', 'in', 'the', 'cold', 'gas', 'atmosphere', 'being', 'set', 'to', 'at', 'least', 'the', 'value', 'of', 'the', 'ambient', 'air', 'pressure', 'method', 'according', 'to', 'clam', 'characterized', 'by', 'forming', 'slush', 'being', 'drained', 'off', 'at', 'least', 'continuously', 'during', 'the', 'production', 'of', 'new', 'slush', 'method', 'according', 'to', 'claim', '9', 'characterized', 'by', 'the', 'slush', 'that', 'is', 'drained', 'being', 'controlled', 'by', 'means', 'of', 'constant', 'measurement', 'of', 'the', 'density', 'method', 'according', 'to', 'claim', '10', 'characterized', 'by', 'the', 'liquefied', 'gas', 'being', 'liquid', 'hydrogen', 'method', 'according', 'to', 'claim', '11', 'characterized', 'by', 'the', 'liquid', 'hydrogen', 'supplied', 'to', 'the', 'atomizing', 'device', 'is', 'cooled', 'down', 'by', 'supply', 'of', 'helium', 'gas', 'method', 'according', 'to', 'claim', '12', 'characterized', 'by', 'a', 'helium', 'gas', 'atmosphere', 'being', 'the', 'cold', 'gas', 'atmosphere', 'a', 'device', 'for', 'producing', 'slush', 'from', 'liquefied', 'gas', 'is', 'a', 'cryostat', 'container', 'which', 'is', 'partly', 'filled', 'with', 'liquefied', 'gas', 'which', 'is', 'mixed', 'with', 'solid', 'crystals', 'to', 'produce', 'slush', 'characterized', 'by', 'an', 'atomizing', 'device', '12', 'for', 'forming', 'liquid', 'particles', 'from', 'supplied', 'liquefied', 'gas', 'to', 'release', 'the', 'liquid', 'particles', 'above', 'the', 'liquefied', 'gas', 'in', 'the', 'container', 'into', 'the', 'gas', 'atmosphere', 'which', 'has', 'an', 'ambient', 'pressure', 'and', 'a', 'temperature', 'below', 'the', 'freezing', 'point', 'of', 'the', 'liquid', 'particles', 'wherein', 'the', 'liquid', 'particles', 'are', 'formed', 'by', 'atomization', 'of', 'the', 'liquefied', 'gas', 'device', 'according', 'to', 'claim', '14', 'characterized', 'by', 'the', 'atomizing', 'device', '12', 'comprising', 'a', 'nozzle', '15a', 'a', 'centrifugal', 'and', 'a', 'mixing', 'chamber', 'device', 'according', 'to', 'claim', '15', 'characterized', 'by', 'the', 'atomizing', 'device', 'having', 'a', 'supply', 'line', 'a', 'to', 'supply', 'pressurized', 'gas', 'device', 'according', 'to', 'claim', '16', 'characterized', 'by', 'the', 'discharge', 'aperture', 'of', 'the', 'nozzle', 'of', 'the', 'atomizing', 'device', 'being', 'selected', 'in', 'such', 'a', 'way', 'that', 'the', 'set', 'pressure', 'there', 'exceeds', 'the', 'pressure', 'in', 'the', 'cold', 'gas', 'atmosphere', 'outside', 'of', 'the', 'atomizing', 'device', 'device', 'according', 'to', 'claim', '17', 'characterized', 'by', 'the', 'atomizing', 'device', '12', 'having', 'at', 'least', 'one', 'supply', 'line', '2b', '17', 'to', 'supply', 'a', 'gaseous', 'cooling', 'medium', 'device', 'according', 'to', 'claim', '18', 'characterized', 'by', 'the', 'atomizing', 'device', 'having', 'gas', 'nozzles', '18', 'to', 'supply', 'the', 'gaseous', 'pressurized', 'cooling', 'medium', 'device', 'according', 'to', 'claim', '19', 'characterized', 'by', 'the', 'atomizing', 'device', 'having', 'a', 'gas', 'guide', 'cone', '13b', 'for', 'the', 'gaseous', 'cooling', 'medium', 'which', 'forms', 'a', 'discharge', 'gap', '16', 'in', 'the', 'area', 'of', 'the', 'nozzle', '15a', 'device', 'according', 'to', 'claim', '20', 'characterized', 'by', 'the', 'supply', 'line', 'of', 'the', 'gas', 'forming', 'the', 'cold', 'gas', 'atmosphere', 'having', 'a', 'number', 'of', 'inlets', 'which', 'are', 'especially', 'arranged', 'like', 'a', 'sprinkler', 'device', 'according', 'to', 'claim', '21', 'characterized', 'by', 'devices', 'being', 'provided', 'for', 'draining', 'off', 'the', 'formed', 'slush', 'and', 'to', 'supplement', 'the', 'quantity', 'of', 'the', 'liquefied', 'gas', 'during', 'the', 'production', 'process', 'device', 'according', 'to', 'claim', '22', 'characterized', 'by', 'having', 'a', 'device', 'for', 'measuring', 'the', 'density', 'of', 'the', 'slush', 'with', 'which', 'the', 'draining', 'off', 'of', 'the', 'slush', 'is', 'controlled', 'device', 'according', 'to', 'claim', '23', 'characterized', 'by', 'liquid', 'hydrogen', 'being', 'the', 'liquefied', 'gas', 'device', 'according', 'to', 'claim', '24', 'characterized', 'by', 'hydrogen', 'being', 'the', 'pressurized', 'gas', 'which', 'is', 'supplied', 'to', 'the', 'atomizing', 'device', 'device', 'according', 'to', 'claim', '18', 'characterized', 'by', 'helium', 'gas', 'being', 'the', 'cooling', 'medium', 'device', 'according', 'to', 'claim', '26', 'characterized', 'by', 'helium', 'gas', 'forming', 'the', 'cold', 'gas', 'temperature', 'device', 'according', 'to', 'claim', '27', 'characterized', 'by', 'having', 'a', 'number', 'of', 'atomizing', 'devices', 'which', 'are', 'arranged', 'in', 'a', 'circular', 'shape']}\n"
     ]
    }
   ],
   "source": [
    "# check if data is successfully created\n",
    "with open('data/train.json') as f:\n",
    "    data = json.load(f)\n",
    "    print(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "cpc_label_tree_path = 'data/cpc_label_tree.pkl'\n",
    "taxonomy_path = 'data/cpc.taxonomy'\n",
    "\n",
    "with open(cpc_label_tree_path,\"rb\") as f:\n",
    "    cpc_label_tree = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(taxonomy_path, \"w\") as f:\n",
    "    \n",
    "    root_dict = cpc_label_tree['Root']\n",
    "    children = \"\\t\".join(root_dict.keys())\n",
    "    f.write(f\"Root\\t{children}\\n\")\n",
    "    \n",
    "    for cpc_section, section_dict in root_dict.items():\n",
    "        \n",
    "        children = \"\\t\".join(section_dict.keys())\n",
    "        f.write(f\"{cpc_section}\\t{children}\\n\")\n",
    "        \n",
    "        for cpc_class, class_dict in section_dict.items():\n",
    "            \n",
    "            children = \"\\t\".join(class_dict.keys())\n",
    "            f.write(f\"{cpc_class}\\t{children}\\n\")\n",
    "            \n",
    "            for cpc_subclass, subclass_dict in class_dict.items():\n",
    "                \n",
    "                children = \"\\t\".join(subclass_dict.keys())\n",
    "                f.write(f\"{cpc_subclass}\\t{children}\\n\")\n",
    "                \n",
    "                for cpc_main_group, main_group_set in subclass_dict.items():\n",
    "                    \n",
    "                    children = \"\\t\".join(main_group_set)\n",
    "                    f.write(f\"{cpc_main_group}\\t{children}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
