{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "import json\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_API_data(directory):\n",
    "    master_df = []\n",
    "    counter = 0\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".p\"):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            with open(file_path, 'rb') as file:\n",
    "                d = pd.DataFrame(pickle.load(file))\n",
    "            master_df.append(d)\n",
    "            counter += 1\n",
    "            print(\"finished processing file {}; count = {}\".format(filename, counter))\n",
    "    return pd.concat(master_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished processing file patent_2M_reparse_0.p; count = 1\n",
      "finished processing file patent_2M_reparse_1.p; count = 2\n"
     ]
    }
   ],
   "source": [
    "API_data_directory = \"data/raw_data\"\n",
    "df_raw = process_API_data(API_data_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice dictionary for cpc field\n",
    "cpc_field_slice_dict = {'kind':                (0 ,2 ),   \n",
    "                        'application_number':  (2 ,10),  \n",
    "                        'document_number':     (10,18),\n",
    "                        'cpc_section':         (18,19), \n",
    "                        'cpc_class':           (18,21), # include higher levels\n",
    "                        'cpc_subclass':        (18,22), # include higher levels\n",
    "                        'cpc_main_group':      (18,26), # include higher levels\n",
    "                        'cpc_subgroup':        (18,33), # include higher levels\n",
    "                        'cpc_version_date':    (33,41), \n",
    "                        'cpc_symbol_position': (41,42), \n",
    "                        'cpc_value_code':      (42,43), \n",
    "                        'cpc_set_group':       (43,46), \n",
    "                        'cpc_set_rank':        (46,48)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of claims\n",
    "len(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_cpc = [y for x in df_raw[\"cpc_codes\"] for y in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "271771"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of labels\n",
    "len(flattened_cpc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create analytics dataset without any text data\n",
    "levels = [\"cpc_section\", \"cpc_class\", \"cpc_subclass\", \"cpc_main_group\", \"cpc_subgroup\"]\n",
    "df_analytics = pd.DataFrame([[cpc[value[0]:value[1]] for key, value in cpc_field_slice_dict.items()] \n",
    "                             for cpc in flattened_cpc],\n",
    "                            columns = list(cpc_field_slice_dict.keys()))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kind</th>\n",
       "      <th>application_number</th>\n",
       "      <th>document_number</th>\n",
       "      <th>cpc_section</th>\n",
       "      <th>cpc_class</th>\n",
       "      <th>cpc_subclass</th>\n",
       "      <th>cpc_main_group</th>\n",
       "      <th>cpc_subgroup</th>\n",
       "      <th>cpc_version_date</th>\n",
       "      <th>cpc_symbol_position</th>\n",
       "      <th>cpc_value_code</th>\n",
       "      <th>cpc_set_group</th>\n",
       "      <th>cpc_set_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>B1</td>\n",
       "      <td>09646314</td>\n",
       "      <td>6405541</td>\n",
       "      <td>F</td>\n",
       "      <td>F25</td>\n",
       "      <td>F25J</td>\n",
       "      <td>F25J   1</td>\n",
       "      <td>F25J   1/001</td>\n",
       "      <td>20130101</td>\n",
       "      <td>F</td>\n",
       "      <td>I</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>B1</td>\n",
       "      <td>09646314</td>\n",
       "      <td>6405541</td>\n",
       "      <td>F</td>\n",
       "      <td>F25</td>\n",
       "      <td>F25J</td>\n",
       "      <td>F25J   1</td>\n",
       "      <td>F25J   1/0221</td>\n",
       "      <td>20130101</td>\n",
       "      <td>L</td>\n",
       "      <td>I</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>B1</td>\n",
       "      <td>09646314</td>\n",
       "      <td>6405541</td>\n",
       "      <td>F</td>\n",
       "      <td>F25</td>\n",
       "      <td>F25J</td>\n",
       "      <td>F25J   1</td>\n",
       "      <td>F25J   1/0275</td>\n",
       "      <td>20130101</td>\n",
       "      <td>L</td>\n",
       "      <td>I</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>B1</td>\n",
       "      <td>09646314</td>\n",
       "      <td>6405541</td>\n",
       "      <td>B</td>\n",
       "      <td>B64</td>\n",
       "      <td>B64G</td>\n",
       "      <td>B64G   1</td>\n",
       "      <td>B64G   1/402</td>\n",
       "      <td>20130101</td>\n",
       "      <td>L</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>B1</td>\n",
       "      <td>09646314</td>\n",
       "      <td>6405541</td>\n",
       "      <td>F</td>\n",
       "      <td>F25</td>\n",
       "      <td>F25J</td>\n",
       "      <td>F25J2205</td>\n",
       "      <td>F25J2205/20</td>\n",
       "      <td>20130101</td>\n",
       "      <td>L</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  kind application_number document_number cpc_section cpc_class cpc_subclass  \\\n",
       "0   B1           09646314         6405541           F       F25         F25J   \n",
       "1   B1           09646314         6405541           F       F25         F25J   \n",
       "2   B1           09646314         6405541           F       F25         F25J   \n",
       "3   B1           09646314         6405541           B       B64         B64G   \n",
       "4   B1           09646314         6405541           F       F25         F25J   \n",
       "\n",
       "  cpc_main_group     cpc_subgroup cpc_version_date cpc_symbol_position  \\\n",
       "0       F25J   1  F25J   1/001            20130101                   F   \n",
       "1       F25J   1  F25J   1/0221           20130101                   L   \n",
       "2       F25J   1  F25J   1/0275           20130101                   L   \n",
       "3       B64G   1  B64G   1/402            20130101                   L   \n",
       "4       F25J2205  F25J2205/20             20130101                   L   \n",
       "\n",
       "  cpc_value_code cpc_set_group cpc_set_rank  \n",
       "0              I             0            0  \n",
       "1              I             0            0  \n",
       "2              I             0            0  \n",
       "3              A             0            0  \n",
       "4              A             0            0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_analytics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique cpc_section: 9\n",
      "number of unique cpc_class: 128\n",
      "number of unique cpc_subclass: 634\n",
      "number of unique cpc_main_group: 7222\n",
      "number of unique cpc_subgroup: 83304\n"
     ]
    }
   ],
   "source": [
    "# number of unique values at differente levels\n",
    "unique_label_dict = {}\n",
    "for level in levels:\n",
    "    unique_label_dict[level] = set(df_analytics[level])\n",
    "    print(\"number of unique \" + level + \": \" + str(len(unique_label_dict[level])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw[\"num_label\"] = df_raw[\"cpc_codes\"].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1237"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# percent of patents with one label\n",
    "len(df_raw[df_raw[\"num_label\"] == 1]) / len(df_raw[\"num_label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5810</td>\n",
       "      <td>14.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5138</td>\n",
       "      <td>12.8%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4948</td>\n",
       "      <td>12.4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4299</td>\n",
       "      <td>10.7%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3409</td>\n",
       "      <td>8.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>181</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>167</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>124 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     count      %\n",
       "2     5810  14.5%\n",
       "3     5138  12.8%\n",
       "1     4948  12.4%\n",
       "4     4299  10.7%\n",
       "5     3409   8.5%\n",
       "..     ...    ...\n",
       "181      1   0.0%\n",
       "167      1   0.0%\n",
       "134      1   0.0%\n",
       "135      1   0.0%\n",
       "78       1   0.0%\n",
       "\n",
       "[124 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([df_raw[\"num_label\"].value_counts(),\n",
    "           df_raw[\"num_label\"].value_counts(normalize=True).mul(100)\n",
    "           .round(1).astype(str)+\"%\"], axis=1, keys=['count', '%'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_column values: ['title', 'abstraction', 'claims', 'brief_summary', 'description']\n",
    "text_columns = ['title', 'abstraction', 'claims']\n",
    "\n",
    "# label_columns values: ['cpc_section', 'cpc_class', 'cpc_subclass', 'cpc_main_group', 'cpc_subgroup']\n",
    "label_columns = ['cpc_section', 'cpc_class', 'cpc_subclass']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_labels(cpc_codes, label_columns):\n",
    "    labels = set()\n",
    "    for cpc_code in cpc_codes:\n",
    "        level_label = []\n",
    "        for label_column in label_columns:\n",
    "            index = cpc_field_slice_dict[label_column]\n",
    "            level_label.append(cpc_code[index[0]:index[1]])\n",
    "        labels.add(\"--\".join(level_label))\n",
    "    return list(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    return [token.lower() for token in tokens if token not in string.punctuation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_data(text_columns, label_columns, folder):\n",
    "    df_text = pd.DataFrame(df_raw['cpc_codes'].apply(extract_labels, args=(label_columns,)))\n",
    "    df_text['doc_token'] = df_raw[text_columns].agg(' '.join, axis=1).apply(tokenize)\n",
    "    df_text.columns = ['doc_label', 'doc_token']\n",
    "    df_text[\"doc_keyword\"] = [[] for _ in range(len(df_text))]\n",
    "    df_text[\"doc_topic\"] = [[] for _ in range(len(df_text))]\n",
    "    \n",
    "    df_train, df_valid_test = train_test_split(df_text, test_size=0.3, random_state=1)\n",
    "    df_valid, df_test = train_test_split(df_valid_test, test_size=0.333, random_state=1)\n",
    "    \n",
    "    df_train.to_json(folder + \"/train.json\", orient='records', lines=True)\n",
    "    df_valid.to_json(folder + \"/valid.json\", orient='records', lines=True)\n",
    "    df_test.to_json(folder + \"/test.json\", orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_data(text_columns, label_columns, 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28000\n",
      "8004\n",
      "3996\n"
     ]
    }
   ],
   "source": [
    "print(sum(1 for line in open('data/train.json')))\n",
    "print(sum(1 for line in open('data/valid.json')))\n",
    "print(sum(1 for line in open('data/test.json')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_json(json_list, output_file):\n",
    "    with open(output_file, \"w\") as outfile:\n",
    "        for input_path in json_list:\n",
    "            with open(input_path) as infile:\n",
    "                print(\"opened {}\".format(input_path))\n",
    "                outfile.write(infile.read())\n",
    "                outfile.write('\\n')\n",
    "            os.remove(input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opened data/valid copy.json\n",
      "opened data/test copy.json\n"
     ]
    }
   ],
   "source": [
    "combine_json(['data/valid copy.json', 'data/test copy.json'], 'data/valid_test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12000\n"
     ]
    }
   ],
   "source": [
    "print(sum(1 for line in open('data/valid_test.json')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'doc_label': ['Y--Y02--Y02W', 'C--C02--C02F', 'B--B01--B01J'], 'doc_token': ['use', 'and', 'regeneration', 'of', 'an', 'adsorbent', 'to', 'remove', 'dyes', 'from', 'water', 'a', 'method', 'of', 'removing', 'at', 'least', 'one', 'cationic', 'dye', 'from', 'an', 'aqueous', 'solution', 'the', 'method', 'includes', 'contacting', 'the', 'aqueous', 'solution', 'with', 'an', 'adsorbent', 'comprising', 'a', 'water-insoluble', 'membrane', 'disposed', 'on', 'a', 'substrate', 'the', 'water-insoluble', 'membrane', 'comprises', 'cross-linked', 'humic', 'acid', 'at', 'least', 'one', 'alginate', 'and', 'hydroxyethyl', 'cellulose', 'the', 'contacting', 'forms', 'a', 'treated', 'aqueous', 'solution', 'having', 'a', 'lower', 'concentration', 'of', 'the', 'at', 'least', 'one', 'cationic', 'dye', 'relative', 'to', 'the', 'aqueous', 'solution', 'a', 'method', 'of', 'removing', 'at', 'least', 'one', 'cationic', 'dye', 'from', 'an', 'aqueous', 'solution', 'comprising', 'pouring', 'an', 'aqueous', 'mixture', 'comprising', 'humic', 'acid', 'at', 'least', 'one', 'alginate', 'and', 'hydroxyethyl', 'cellulose', 'onto', 'a', 'substrate', 'to', 'form', 'a', 'film', 'drying', 'the', 'film', 'and', 'crosslinking', 'the', 'film', 'with', 'glutaraldehyde', 'to', 'form', 'a', 'first', 'water-insoluble', 'membrane', 'disposed', 'on', 'the', 'substrate', 'then', 'contacting', 'the', 'aqueous', 'solution', 'with', 'an', 'adsorbent', 'comprising', 'the', 'first', 'water-insoluble', 'membrane', 'disposed', 'on', 'the', 'substrate', 'wherein', 'the', 'first', 'water-insoluble', 'membrane', 'consists', 'essentially', 'of', 'glutaraldehyde-cross-linked', 'humic', 'acid', 'at', 'least', 'one', 'alginate', 'and', 'hydroxyethyl', 'cellulose', 'wherein', 'the', 'weight', 'ratio', 'of', 'humic', 'acid', 'at', 'least', 'one', 'alginate', 'hydroxyethyl', 'cellulose', 'lies', 'in', 'the', 'range', '10-20', '60-80', '10-20', 'respectively', 'and', 'wherein', 'the', 'contacting', 'forms', 'a', 'treated', 'aqueous', 'solution', 'having', 'a', 'lower', 'concentration', 'of', 'the', 'at', 'least', 'one', 'cationic', 'dye', 'relative', 'to', 'the', 'aqueous', 'solution', 'and', 'the', 'contacting', 'forms', 'a', 'dye-adsorbed', 'water-insoluble', 'membrane', 'then', 'treating', 'the', 'dye-adsorbed', 'water-insoluble', 'membrane', 'with', 'an', 'hcl', 'solution', 'to', 'remove', 'the', 'dye', 'from', 'the', 'dye-adsorbed', 'water-insoluble', 'membrane', 'and', 'to', 'regenerate', 'the', 'first', 'water-insoluble', 'membrane', 'the', 'method', 'of', 'claim', '1', 'wherein', 'the', 'ph', 'of', 'the', 'aqueous', 'solution', 'ranges', 'from', 'about', '3', 'to', 'about', '10', 'the', 'method', 'of', 'claim', '1', 'wherein', 'the', 'at', 'least', 'one', 'cationic', 'dye', 'is', 'selected', 'from', 'the', 'group', 'consisting', 'of', 'methylene', 'blue', 'rhodamine', 'b', 'crystal', 'violet', 'basic', 'fuchsin', 'safranin', 'pararosaniline', 'and', 'a', 'combination', 'thereof', 'the', 'method', 'of', 'claim', '1', 'wherein', 'the', 'adsorbent', 'is', 'disposed', 'in', 'a', 'fixed', 'bed', 'reactor', 'or', 'fluidized', 'bed', 'reactor', 'and', 'the', 'contacting', 'involves', 'passing', 'the', 'aqueous', 'solution', 'through', 'the', 'fixed', 'bed', 'reactor', 'or', 'fluidized', 'bed', 'reactor', 'the', 'method', 'of', 'claim', '4', 'wherein', 'the', 'adsorbent', 'is', 'disposed', 'in', 'a', 'fixed', 'bed', 'reactor', 'that', 'comprises', 'a', 'cartridge', 'the', 'method', 'of', 'claim', '5', 'wherein', 'the', 'cartridge', 'further', 'comprises', 'activated', 'carbon', 'the', 'method', 'of', 'claim', '1', 'wherein', 'the', 'adsorbent', 'has', 'a', 'form', 'selected', 'from', 'the', 'group', 'consisting', 'of', 'a', 'granule', 'a', 'pellet', 'a', 'sphere', 'a', 'powder', 'a', 'woven', 'fabric', 'a', 'non-woven', 'fabric', 'a', 'mat', 'a', 'felt', 'a', 'block', 'and', 'a', 'honeycomb', 'the', 'method', 'of', 'claim', '1', 'wherein', 'the', 'aqueous', 'solution', 'is', 'contacted', 'with', 'the', 'adsorbent', 'at', 'a', 'temperature', 'of', 'about', '10-90°', 'c.', 'and', 'a', 'pressure', 'of', 'about', '1-50', 'bar'], 'doc_keyword': [], 'doc_topic': []}\n"
     ]
    }
   ],
   "source": [
    "# check if data is successfully created\n",
    "with open('data/train.json') as f:\n",
    "    data = json.load(f)\n",
    "    print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('data/train.json') as f:\n",
    "    for _json_str in f:\n",
    "        print(_json_str)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "cpc_label_tree_path = 'data/cpc_label_tree.pkl'\n",
    "taxonomy_path = 'data/cpc.taxonomy'\n",
    "\n",
    "with open(cpc_label_tree_path,\"rb\") as f:\n",
    "    cpc_label_tree = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(taxonomy_path, \"w\") as f:\n",
    "    \n",
    "    root_dict = cpc_label_tree['Root']\n",
    "    children = \"\\t\".join(root_dict.keys())\n",
    "    f.write(f\"Root\\t{children}\\n\")\n",
    "    \n",
    "    for cpc_section, section_dict in root_dict.items():\n",
    "        \n",
    "        children = \"\\t\".join(section_dict.keys())\n",
    "        f.write(f\"{cpc_section}\\t{children}\\n\")\n",
    "        \n",
    "        for cpc_class, class_dict in section_dict.items():\n",
    "            \n",
    "            children = \"\\t\".join(class_dict.keys())\n",
    "            f.write(f\"{cpc_class}\\t{children}\\n\")\n",
    "            \n",
    "            for cpc_subclass, subclass_dict in class_dict.items():\n",
    "                \n",
    "                children = \"\\t\".join(subclass_dict.keys())\n",
    "                f.write(f\"{cpc_subclass}\\t{children}\\n\")\n",
    "                \n",
    "                for cpc_main_group, main_group_set in subclass_dict.items():\n",
    "                    \n",
    "                    children = \"\\t\".join(main_group_set)\n",
    "                    f.write(f\"{cpc_main_group}\\t{children}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-e311f29bb25f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "for i in None:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
