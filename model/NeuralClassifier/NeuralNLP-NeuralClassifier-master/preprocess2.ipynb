{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice dictionary for cpc field\n",
    "cpc_field_slice_dict = {'kind':                (0 ,2 ),   \n",
    "                        'application_number':  (2 ,10),  \n",
    "                        'document_number':     (10,18),\n",
    "                        'cpc_section':         (18,19), \n",
    "                        'cpc_class':           (18,21), # include higher levels\n",
    "                        'cpc_subclass':        (18,22), # include higher levels\n",
    "                        'cpc_main_group':      (18,26), # include higher levels\n",
    "                        'cpc_subgroup':        (18,33), # include higher levels\n",
    "                        'cpc_version_date':    (33,41), \n",
    "                        'cpc_symbol_position': (41,42), \n",
    "                        'cpc_value_code':      (42,43), \n",
    "                        'cpc_set_group':       (43,46), \n",
    "                        'cpc_set_rank':        (46,48)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_labels(cpc_codes, label_columns):\n",
    "    labels = set()\n",
    "    for cpc_code in cpc_codes:\n",
    "        level_label = []\n",
    "        for label_column in label_columns:\n",
    "            index = cpc_field_slice_dict[label_column]\n",
    "            level_label.append(cpc_code[index[0]:index[1]])\n",
    "        labels.add(\"--\".join(level_label))\n",
    "    return list(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    return [token.lower() for token in tokens if token not in string.punctuation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_single_API_data(input_path, output_path):\n",
    "    with open(input_path, 'rb') as file:\n",
    "        df = pd.DataFrame(pickle.load(file))\n",
    "        \n",
    "    df_text = pd.DataFrame(df['cpc_codes'].apply(extract_labels, args=(label_columns,)))\n",
    "    df_text['doc_token'] = df[text_columns].agg(' '.join, axis=1).apply(tokenize)\n",
    "    df_text.columns = ['doc_label', 'doc_token']\n",
    "    df_text.to_json(output_path, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_API_data_folder(input_directory, output_directory):\n",
    "    counter = 0\n",
    "    for filename in os.listdir(input_directory):\n",
    "        if filename.endswith(\".p\"):\n",
    "            input_path = os.path.join(input_directory, filename)\n",
    "            output_path = os.path.join(output_directory, \"post_\"+filename)\n",
    "            process_single_API_data(input_path, output_path)\n",
    "            counter += 1\n",
    "            print(\"finished processing file {}; count = {}\".format(filename, counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_json(json_list, output_file):\n",
    "    with open(output_file, \"w\") as outfile:\n",
    "        first = True\n",
    "        for input_path in json_list:\n",
    "            with open(input_path) as infile:\n",
    "                print(\"opened {}\".format(input_path))\n",
    "                if first:\n",
    "                    outfile.write('[')\n",
    "                    first = False\n",
    "                else:\n",
    "                    outfile.write(',')\n",
    "                outfile.write(infile.read().strip()[1:-1])\n",
    "            os.remove(input_path)\n",
    "        outfile.write(']')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_json_list(output_directory, start_index, end_index, base_name):\n",
    "    return [os.path.join(output_directory, base_name.format(i)) for i in range(start_index, end_index+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_directory = \"data/raw_data\"\n",
    "output_directory = \"data\"\n",
    "\n",
    "# text_column values: ['title', 'abstraction', 'claims', 'brief_summary', 'description']\n",
    "text_columns = ['title', 'abstraction', 'claims']\n",
    "\n",
    "# label_columns values: ['cpc_section', 'cpc_class', 'cpc_subclass', 'cpc_main_group', 'cpc_subgroup']\n",
    "label_columns = ['cpc_section', 'cpc_class', 'cpc_subclass']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_start_index = 0\n",
    "train_end_index = 12\n",
    "valid_start_index = 16\n",
    "valid_end_index = 17\n",
    "test_start_index = 13\n",
    "test_end_index = 15\n",
    "base_name = \"post_patent_2M_reparse_{}.p\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished processing file patent_2M_reparse_0.p; count = 1\n",
      "finished processing file patent_2M_reparse_1.p; count = 2\n"
     ]
    }
   ],
   "source": [
    "process_API_data_folder(input_directory, output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_json_list = get_json_list(output_directory, train_start_index, train_end_index, base_name)\n",
    "valid_json_list = get_json_list(output_directory, valid_start_index, valid_end_index, base_name)\n",
    "test_json_list = get_json_list(output_directory, test_start_index, test_end_index, base_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opened data/post_patent_2M_reparse_0.p\n",
      "opened data/post_patent_2M_reparse_1.p\n"
     ]
    }
   ],
   "source": [
    "combine_json(train_json_list, os.path.join(output_directory, \"train.json\"))\n",
    "combine_json(valid_json_list, os.path.join(output_directory, \"valid.json\"))\n",
    "combine_json(test_json_list, os.path.join(output_directory, \"test.json\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
